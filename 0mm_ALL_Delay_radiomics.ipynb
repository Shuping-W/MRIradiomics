{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "                            \n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlsx1_filepath = r\"F:\\Newdataset\\muilt_ROI\\feature_extract\\norm_ALL_CC_Delay.xlsx\"\n",
    "xlsx2_filepath = r\"F:\\Newdataset\\muilt_ROI\\feature_extract\\norm_ALL_HCC_Delay.xlsx\"\n",
    "\n",
    "data_1 = pd.read_excel(xlsx1_filepath)\n",
    "data_2 = pd.read_excel(xlsx2_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rows1,cols1 = data_1.shape\n",
    "rows2,cols2 = data_2.shape\n",
    "# print(rows1,cols1)\n",
    "# data_1.head()\n",
    "# print(data_1.columns) \n",
    "\n",
    "\n",
    "data_1.insert(0,'label',[0]*rows1)  #CC\n",
    "data_2.insert(0,'label',[1]*rows2)  #HCC\n",
    "\n",
    "data = pd.concat([data_1,data_2])\n",
    "# data.head(10)\n",
    "\n",
    "data = shuffle(data)\n",
    "\n",
    "x = data[data.columns[1:]]\n",
    "y = data['label']\n",
    "colNames = x.columns\n",
    "x = x.astype(np.float64)\n",
    "X1 = StandardScaler().fit_transform(x) \n",
    "X1 = pd.DataFrame(X1)\n",
    "X1.columns = colNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import feature_selection\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import chi2\n",
    "mi = SelectKBest(mutual_info_classif,k = 200).fit(X1,y)\n",
    "len(X1.columns[mi.get_support()])\n",
    "X_mi=mi.transform(X1)\n",
    "\n",
    "X_mi = pd.DataFrame(X_mi)\n",
    "X_mi.columns = X1.columns[mi.get_support()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "rfe = RFE(RandomForestClassifier(n_estimators=100,random_state=0),n_features_to_select=100,step=10)\n",
    "rfe.fit(X_mi,y)\n",
    "\n",
    "X_features = X_mi.columns[rfe.get_support(True)]\n",
    "\n",
    "X1=X1[X_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "alphas = np.logspace(-5,3,100) \n",
    "# print(alphas)\n",
    "model_lassoCV = LassoCV(alphas = alphas, cv = 10, max_iter = 100000).fit(X1,y)  \n",
    "print('The Optimal alpha is :',model_lassoCV.alpha_)  \n",
    "print('--------------------')\n",
    "coef = pd.Series(model_lassoCV.coef_ ,index = X1.columns) \n",
    "\n",
    "print('LASSO selected ' + str(sum(coef != 0)) + ' variable and eliminated the other' +  str(sum(coef == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = coef[coef != 0 ].index\n",
    "X1 = X1[index]\n",
    "print(coef[coef != 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig=plt.figure(num=None, figsize=(8,6), dpi=300, facecolor='w', edgecolor='k')\n",
    "\n",
    "top_coef = abs(coef).sort_values()\n",
    "top_coef[top_coef != 0].plot(kind = \"barh\",color = 'slateblue')\n",
    "plt.title(\"Most Important Selected Features For E0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X1,y,test_size = 0.2)\n",
    "model_svm = svm.SVC(kernel='rbf',gamma = 'auto',probability = True).fit(x_train,y_train)\n",
    "score_svm1 = model_svm.score(x_train,y_train)\n",
    "score_svm2 = model_svm.score(x_test,y_test)\n",
    "print(score_svm1)\n",
    "print(score_svm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  from sklearn.model_selection import GridSearchCV\n",
    "Cs = np.logspace(-1,3,50,base = 2)\n",
    "gammas = np.logspace(-4,4,50,base = 2)\n",
    "param_grid = dict(C = Cs,gamma = gammas)\n",
    "grid = GridSearchCV(svm.SVC(kernel='rbf'),param_grid = param_grid,cv = 5).fit(X1,y)\n",
    "print(grid.best_params_)\n",
    "\n",
    "#c：1.8372539081409516   g:0.07837463407059186"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "C = grid.best_params_['C']\n",
    "gamma = grid.best_params_['gamma']\n",
    "x_train,x_test,y_train,y_test = train_test_split(X1,y,test_size = 0.3)\n",
    "model_svm = svm.SVC(C = C,kernel='rbf',gamma =gamma,probability = True).fit(x_train,y_train)\n",
    "score_svm_train = model_svm.score(x_train,y_train)\n",
    "score_svm_test = model_svm.score(x_test,y_test)\n",
    "print(score_svm_train)\n",
    "print(score_svm_test)\n",
    "\n",
    "# model_cv = cross_val_score(model_svm,X1,y,cv = 10).mean()\n",
    "# print(model_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test)\n",
    "print((y_test).values)\n",
    "print(y_pred)\n",
    "\n",
    "from sklearn.metrics import accuracy_score,precision_score, \\\n",
    "recall_score,f1_score,cohen_kappa_score\n",
    "print('ACC：',\n",
    "      accuracy_score(y_test,y_pred))\n",
    "print('precision：',\n",
    "      precision_score(y_test,y_pred))\n",
    "print('recall：',\n",
    "      recall_score(y_test,y_pred))\n",
    "print('f1_score：',\n",
    "      f1_score(y_test,y_pred))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve,roc_auc_score,auc\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8,6))\n",
    "#AUC\n",
    "y_probs = model_svm.predict_proba(x_test)   \n",
    "# # print(y_probs)                  \n",
    "# # print(y_probs[:,1])\n",
    "fpr,tpr,thresholds = roc_curve(y_test,y_probs[:,1],pos_label = 1)\n",
    "\n",
    "auc_score = auc(fpr,tpr)\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=2, label='ROC curve (AUC = %0.2f)' % auc_score)\n",
    "# plt.plot(fpr,tpr,marker = '')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC for SVM')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "x_train,x_test,y_train,y_test = train_test_split(X1,y,test_size = 0.3)\n",
    "model_rf = ensemble.RandomForestClassifier(n_estimators = 50)\n",
    "model_rf.fit(x_train,y_train)\n",
    "score_train = model_rf.score(x_train,y_train)\n",
    "score_test = model_rf.score(x_test,y_test)\n",
    "# result = model_rf.predict(X_test)\n",
    "print(score_train)\n",
    "print(score_test)\n",
    "# print(y_test)\n",
    "# print(result)\n",
    "\n",
    "# model_cv = cross_val_score(model_rf,X,y,cv = 10).mean()\n",
    "# print(model_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test)\n",
    "print((y_test).values)\n",
    "print(y_pred)\n",
    "\n",
    "from sklearn.metrics import accuracy_score,precision_score, \\\n",
    "recall_score,f1_score,cohen_kappa_score\n",
    "print('ACC：',\n",
    "      accuracy_score(y_test,y_pred))\n",
    "print('precision：',\n",
    "      precision_score(y_test,y_pred))\n",
    "print('recall：',\n",
    "      recall_score(y_test,y_pred))\n",
    "print('f1_score：',\n",
    "      f1_score(y_test,y_pred))\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve,roc_auc_score,auc\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "y_probs = model_rf.predict_proba(x_test) \n",
    "# # print(y_probs)                  \n",
    "# # print(y_probs[:,1])\n",
    "fpr,tpr,thresholds = roc_curve(y_test,y_probs[:,1],pos_label = 1)\n",
    "\n",
    "auc_score = auc(fpr,tpr)\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=2, label='ROC curve (AUC = %0.2f)' % auc_score)\n",
    "# plt.plot(fpr,tpr,marker = '')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC for RF')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(X1,y,test_size = 0.3)\n",
    "model_NN = MLPClassifier(activation='relu', solver='adam', alpha=0.001)\n",
    "model_NN.fit(x_train,y_train)\n",
    "score_train = model_NN.score(x_train,y_train)\n",
    "score_test = model_NN.score(x_test,y_test)\n",
    "print(score_train)\n",
    "print(score_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test)\n",
    "print((y_test).values)\n",
    "print(y_pred)\n",
    "\n",
    "from sklearn.metrics import accuracy_score,precision_score, \\\n",
    "recall_score,f1_score,cohen_kappa_score\n",
    "print('ACC：',\n",
    "      accuracy_score(y_test,y_pred))\n",
    "print('precision：',\n",
    "      precision_score(y_test,y_pred))\n",
    "print('recall：',\n",
    "      recall_score(y_test,y_pred))\n",
    "print('f1_score：',\n",
    "      f1_score(y_test,y_pred))\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve,roc_auc_score,auc\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8,6))\n",
    "#AUC\n",
    "y_probs = model_NN.predict_proba(x_test)  \n",
    "# # print(y_probs)                 \n",
    "# # print(y_probs[:,1])\n",
    "fpr,tpr,thresholds = roc_curve(y_test,y_probs[:,1],pos_label = 1)\n",
    "\n",
    "auc_score = auc(fpr,tpr)\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=2, label='ROC curve (AUC = %0.2f)' % auc_score)\n",
    "# plt.plot(fpr,tpr,marker = '')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC for RF')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from xgboost import XGBClassifier\n",
    "X_train,X_test,y_train,y_test = train_test_split(X1,y,test_size = 0.3)\n",
    "clf = XGBClassifier(max_depth=5, learning_rate=0.1, n_estimators=100)\n",
    "clf.fit(X_train, y_train)\n",
    "train_predict = clf.predict(X_train)\n",
    "test_predict = clf.predict(X_test)\n",
    "print(metrics.accuracy_score(y_train,train_predict))\n",
    "print(metrics.accuracy_score(y_test,test_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test)\n",
    "print((y_test).values)\n",
    "print(y_pred)\n",
    "\n",
    "from sklearn.metrics import accuracy_score,precision_score, \\\n",
    "recall_score,f1_score,cohen_kappa_score\n",
    "print('ACC：',\n",
    "      accuracy_score(y_test,y_pred))\n",
    "print('precision：',\n",
    "      precision_score(y_test,y_pred))\n",
    "print('recall：',\n",
    "      recall_score(y_test,y_pred))\n",
    "print('f1_score：',\n",
    "      f1_score(y_test,y_pred))\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "y_probs = clf.predict_proba(X_test)   \n",
    "# # print(y_probs)                  \n",
    "# # print(y_probs[:,1])\n",
    "fpr,tpr,thresholds = roc_curve(y_test,y_probs[:,1],pos_label = 1)\n",
    "\n",
    "auc_score = auc(fpr,tpr)\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=2, label='ROC curve (AUC = %0.2f)' % auc_score)\n",
    "# plt.plot(fpr,tpr,marker = '')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC for XGBoost')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
